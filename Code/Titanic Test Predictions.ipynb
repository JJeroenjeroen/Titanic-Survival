{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict the testset!\n",
    "\n",
    "Allright so this file will do essentially the same things as the previous exploratory file, but now it will execute all the preprocessing on the test set so that the predictions can be generated which will be used for in Kaggles competition (https://www.kaggle.com/c/titanic/). These predicions are in the end saved to a csv file to use in the competition\n",
    "\n",
    "If anyone has taken the time to read through this kernel, I hope you have enjoyed. \n",
    "Cheers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#call libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pylab\n",
    "import math\n",
    "import seaborn as sns\n",
    "\n",
    "# Set default matplot figure size\n",
    "pylab.rcParams['figure.figsize'] = (6.5, 5.0)\n",
    "\n",
    "#Turn off pandas warning for changing variables & future warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "#set random seed\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import dataset and look at what information we are dealing with\n",
    "titanic = pd.read_csv(\"C:\\\\Users\\\\Jeroen\\\\Desktop\\\\Kaggle Datasets\\\\Titanic\\\\Excel Files\\\\test.csv\", header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dummy variable for married by looping over whether passangers names' contain Mr. or Mrs.\n",
    "titanic[\"Mr.\"] = 0\n",
    "for i in range(0,len(titanic[\"Name\"])):\n",
    "    if \"Mr.\" in titanic.loc[i][\"Name\"]:\n",
    "        titanic.at[i, \"Mr.\"] = 1\n",
    "\n",
    "titanic[\"Mrs.\"] = 0\n",
    "for i in range(0,len(titanic[\"Name\"])):\n",
    "    if \"Mrs.\" in titanic.loc[i][\"Name\"]:\n",
    "        titanic.at[i, \"Mrs.\"] = 1\n",
    "        \n",
    "titanic[\"Miss.\"] = 0\n",
    "for i in range(0,len(titanic[\"Name\"])):\n",
    "    if \"Miss.\" in titanic.loc[i][\"Name\"]:\n",
    "        titanic.at[i, \"Miss.\"] = 1        \n",
    "\n",
    "                \n",
    "titanic[\"Master.\"] = 0\n",
    "for i in range(0,len(titanic[\"Name\"])):\n",
    "    if \"Master.\" in titanic.loc[i][\"Name\"]:\n",
    "        titanic.at[i, \"Master.\"] = 1\n",
    "        \n",
    "titanic[\"Other_Title\"] = 1 - (titanic[\"Master.\"] + titanic[\"Miss.\"] + titanic[\"Mrs.\"] + titanic[\"Mr.\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate a zero ticket fare variable\n",
    "titanic[\"Zero_ticket_fare\"] = 0\n",
    "for i in range(0,len(titanic[\"Fare\"])):\n",
    "    if titanic.loc[i][\"Fare\"] == 0:\n",
    "        titanic.at[i, \"Zero_ticket_fare\"] = 1\n",
    "\n",
    "\n",
    "#locate and change ticket nr.\n",
    "titanic.loc[(titanic.Ticket == \"LINE\"), \"Ticket\"] = str(370160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticket_counts = titanic['Ticket'].value_counts()\n",
    "ticket_counts = pd.Series.to_frame(ticket_counts)\n",
    "ticket_counts[\"Ticket_nr\"] = ticket_counts.index\n",
    "ticket_counts.index = range(0,len(ticket_counts))\n",
    "ticket_counts.columns = [\"Ticket_group_size\", \"Ticket\"]\n",
    "titanic = pd.merge(titanic, ticket_counts, how='outer', on='Ticket')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now calculate the actual ticket value\n",
    "titanic[\"Price_per_person\"] = (titanic[\"Fare\"] / titanic[\"Ticket_group_size\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate dummies for the class variable\n",
    "class_dummies = pd.get_dummies(titanic.Pclass)\n",
    "class_dummies.columns = [\"First_class\", \"Second_class\", \"Third_class\"]\n",
    "titanic = pd.concat([titanic, class_dummies], axis=1, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate dummies for where the ship embarked\n",
    "embarked_dummies = pd.get_dummies(titanic.Embarked)\n",
    "embarked_dummies.columns = [\"Southampton\", \"Cherbourg\", \"Queenstown\"]\n",
    "titanic = pd.concat([titanic, embarked_dummies], axis=1, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_PassengerId = titanic[\"PassengerId\"]\n",
    "titanic = titanic.drop(columns = \"PassengerId\")\n",
    "titanic = titanic.drop(columns = \"Ticket\")\n",
    "titanic = titanic.drop(columns = \"Name\")\n",
    "titanic = titanic.drop(columns = \"Cabin\")\n",
    "titanic = titanic.drop(columns = \"Fare\")\n",
    "titanic = titanic.drop(columns = \"Pclass\")\n",
    "titanic = titanic.drop(columns = \"Embarked\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_indep = titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_indep[\"Sex\"] = titanic_indep.Sex.astype('category')\n",
    "titanic_indep[\"First_class\"] = titanic_indep.First_class.astype('category')\n",
    "titanic_indep[\"Second_class\"] = titanic_indep.Second_class.astype('category')\n",
    "titanic_indep[\"Third_class\"] = titanic_indep.Third_class.astype('category')\n",
    "titanic_indep[\"Southampton\"] = titanic_indep.Southampton.astype('category')\n",
    "titanic_indep[\"Cherbourg\"] = titanic_indep.Cherbourg.astype('category')\n",
    "titanic_indep[\"Queenstown\"] = titanic_indep.Queenstown.astype('category')\n",
    "\n",
    "#convert all categories into numerical variables so they can be proberly used to model with\n",
    "titanic_indep.Sex = pd.CategoricalIndex(titanic_indep.Sex)\n",
    "titanic_indep.First_class = pd.CategoricalIndex(titanic_indep.First_class)\n",
    "titanic_indep.Second_class = pd.CategoricalIndex(titanic_indep.Second_class)\n",
    "titanic_indep.Third_class = pd.CategoricalIndex(titanic_indep.Third_class)\n",
    "titanic_indep.Southampton = pd.CategoricalIndex(titanic_indep.Southampton)\n",
    "titanic_indep.Cherbourg = pd.CategoricalIndex(titanic_indep.Cherbourg)\n",
    "\n",
    "titanic_indep['Sex'] = titanic_indep.Sex.cat.codes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NA's make it difficult to normalize the dataframe, therefore, do it seperately \n",
    "agecolumn = titanic_indep[\"Age\"]\n",
    "Ages_noNA = agecolumn[agecolumn > -1]\n",
    "Ages_yesNa = agecolumn[agecolumn.isna()]\n",
    "\n",
    "Ages_noNA = (Ages_noNA - Ages_noNA.mean()) / (Ages_noNA.max() - Ages_noNA.min())\n",
    "agecolumn = Ages_noNA.append(Ages_yesNa, ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "restcolumns = titanic_indep.loc[:, titanic_indep.columns != \"Age\"]\n",
    "restcolumns = restcolumns.apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in (range(0, len(list(restcolumns)))):\n",
    "    restcolumns.iloc[:,[i]] = (restcolumns.iloc[:,[i]] - restcolumns.iloc[:,[i]].mean()) / (restcolumns.iloc[:,[i]].max() - restcolumns.iloc[:,[i]].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "restcolumns[\"Age\"] = agecolumn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_indep = restcolumns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing row 1/418 with 0 missing, elapsed time: 0.044\n",
      "Imputing row 101/418 with 1 missing, elapsed time: 0.046\n",
      "Imputing row 201/418 with 0 missing, elapsed time: 0.047\n",
      "Imputing row 301/418 with 1 missing, elapsed time: 0.049\n",
      "Imputing row 401/418 with 0 missing, elapsed time: 0.050\n"
     ]
    }
   ],
   "source": [
    "from fancyimpute import KNN\n",
    "#We use the train dataframe from Titanic dataset\n",
    "#fancy impute removes column names.\n",
    "titanic_cols = list(titanic_indep)\n",
    "# Use 5 nearest rows which have a feature to fill in each row's\n",
    "# missing features\n",
    "titanic_indep = pd.DataFrame(KNN(k = 9).fit_transform(titanic_indep))\n",
    "titanic_indep.columns = titanic_cols\n",
    "titanic_indep[\"Age\"] = round(titanic_indep[\"Age\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "#imort the logistic regression model   \n",
    "filename = 'Logistic_reg_model.sav'\n",
    "Logistic_reg_model = pickle.load(open(filename, 'rb'))\n",
    "log_regression_result = Logistic_reg_model.predict(titanic_indep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_final_file = pd.DataFrame()\n",
    "titanic_final_file[\"PassengerId\"] = titanic_PassengerId\n",
    "titanic_final_file[\"Survived\"] = log_regression_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_final_file.to_csv(r'C:\\Users\\Jeroen\\Desktop\\Kaggle Datasets\\Titanic\\Code\\Titanic Predictions.csv', index = None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
